# The Ecosystem around GPT, from 1 to 3.5 and ChatGPT.
This was especially inspired by two factors:

1. The rise of rise of [ChatGPT](https://chat.openai.com/chat).
2. [This amazing repo](https://github.com/karpathy/minGPT) by Andrej Karpathy, which implements an educational, minimal version of the GPT language model. 

## Basic references 
GPT is developed by OpenAI and not eerything about the models is public. However, there are some basic papers which lead to the current state of [GPT](https://openai.com/blog/chatgpt/).

1. [Improving Language Understanding
by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) 
2. [Language Models are Unsupervised Multitask Learners
](https://paperswithcode.com/paper/language-models-are-unsupervised-multitask)
3. [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
4. [Generative Pretraining from Pixels](https://paperswithcode.com/paper/generative-pretraining-from-pixels)
5. [Training language models to follow instructions with human feedback
](https://arxiv.org/abs/2203.02155)